Index: src/test/org/apache/hadoop/mapreduce/TestShufflePlugin.java
===================================================================
--- src/test/org/apache/hadoop/mapreduce/TestShufflePlugin.java	(revision 0)
+++ src/test/org/apache/hadoop/mapreduce/TestShufflePlugin.java	(revision 0)
@@ -0,0 +1,97 @@
+/**
+	* Licensed to the Apache Software Foundation (ASF) under one
+	* or more contributor license agreements.  See the NOTICE file
+	* distributed with this work for additional information
+	* regarding copyright ownership.  The ASF licenses this file
+	* to you under the Apache License, Version 2.0 (the
+	* "License"); you may not use this file except in compliance
+	* with the License.  You may obtain a copy of the License at
+	*
+	*     http://www.apache.org/licenses/LICENSE-2.0
+	*
+	* Unless required by applicable law or agreed to in writing, software
+	* distributed under the License is distributed on an "AS IS" BASIS,
+	* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+	* See the License for the specific language governing permissions and
+	* limitations under the License.
+*/
+
+package org.apache.hadoop.mapreduce;
+
+import org.junit.Test;
+import static org.junit.Assert.*;
+import static org.mockito.Mockito.*;
+
+import org.apache.hadoop.mapred.ShuffleProviderPlugin;
+import org.apache.hadoop.mapred.TaskTracker;
+import org.apache.hadoop.mapred.TaskController;
+import org.apache.hadoop.mapred.JobConf;
+import org.apache.hadoop.mapred.JobID;
+
+import org.apache.hadoop.mapred.ShuffleConsumerPlugin;
+import org.apache.hadoop.mapred.ReduceTask;
+import org.apache.hadoop.mapred.TaskUmbilicalProtocol;
+import org.apache.hadoop.mapred.Reporter;
+import org.apache.hadoop.fs.LocalFileSystem;
+
+
+/**
+  * A JUnit test for testing availability and accessibility of main API that is needed
+  * for sub-classes of ShuffleProviderPlugin and ShuffleConsumerPlugin.
+  * The importance of this test is for preserving API with 3rd party plugins.
+  */
+public class TestShufflePlugin {
+	
+	@Test
+	/**
+	 * A method for testing availability and accessibility of API that is needed for sub-classes of ShuffleProviderPlugin
+	 */
+	public void testProvider() {
+		//mock creation
+		ShuffleProviderPlugin mockShuffleProvider = mock(ShuffleProviderPlugin.class);
+		TaskTracker mockTT = mock(TaskTracker.class);
+		TaskController mockTaskController = mock(TaskController.class);
+		
+		mockShuffleProvider.initialize(mockTT);
+		mockShuffleProvider.destroy();
+		
+		mockTT.getJobConf();
+		mockTT.getJobConf(mock(JobID.class));
+		mockTT.getIntermediateOutputDir("","","");
+		mockTT.getTaskController();
+		
+		mockTaskController.getRunAsUser(mock(JobConf.class));
+	}
+	
+	@Test
+	/**
+	 * A method for testing availability and accessibility of API that is needed for sub-classes of ShuffleConsumerPlugin
+	 */
+	public void testConsumer() {
+		//mock creation
+		ShuffleConsumerPlugin mockShuffleConsumer = mock(ShuffleConsumerPlugin.class);
+		ReduceTask mockReduceTask = mock(ReduceTask.class);
+		JobConf mockJobConf = mock(JobConf.class);
+		TaskUmbilicalProtocol mockUmbilical = mock(TaskUmbilicalProtocol.class);
+		Reporter mockReporter = mock(Reporter.class);
+		LocalFileSystem mockLocalFileSystem = mock(LocalFileSystem.class);
+		
+		mockReduceTask.getTaskID();
+		mockReduceTask.getJobID();
+		mockReduceTask.getNumMaps();
+		mockReduceTask.getPartition();
+		mockReduceTask.getJobFile();
+		mockReduceTask.getJvmContext();
+		
+		mockReporter.progress();
+		
+		try {
+			String [] dirs = mockJobConf.getLocalDirs();
+			mockShuffleConsumer.init(mockReduceTask, mockUmbilical, mockJobConf, mockReporter);
+			mockShuffleConsumer.fetchOutputs();
+			mockShuffleConsumer.createKVIterator(mockJobConf, mockLocalFileSystem.getRaw(), mockReporter);
+			mockShuffleConsumer.close();
+		}
+		catch (java.io.IOException e){}
+	}
+}
Index: src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java
===================================================================
--- src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java	(revision 0)
+++ src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java	(revision 0)
@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+
+/**
+ * This interface is implemented by objects that are able to answer shuffle requests which are
+ * sent from a matching Shuffle Consumer that lives in context of a ReduceTask object.
+ * 
+ * ShuffleProviderPlugin object will be notified on the following events: 
+ * initialize, destroy.
+ * At this phase, at most one optional ShuffleProvider is supported by TaskTracker 
+ * At this phase, TaskTracker will use the optional ShuffleProvider (if any) in addition to 
+ * the default shuffle provider (MapOutputServlet).
+ * 
+ * NOTE: This interface is also used when loading 3rd party plugins at runtime
+ *
+ */
+public interface ShuffleProviderPlugin {
+	/**
+	 * Do the real constructor work here.  It's in a separate method
+	 * so we can call it again and "recycle" the object after calling
+	 * destroy().
+	 * 
+	 * invoked from TaskTracker.initialize
+	 */
+	public void initialize(TaskTracker taskTracker);
+	
+	/**
+	 * close and cleanup any resource, including threads and disk space.  
+	 * A new object within the same process space might be restarted, 
+	 * so everything must be clean.
+	 * 
+	 * invoked from TaskTracker.close
+	 */
+	public void destroy();	
+}
Index: src/mapred/org/apache/hadoop/mapred/TaskTracker.java
===================================================================
--- src/mapred/org/apache/hadoop/mapred/TaskTracker.java	(revision 1363325)
+++ src/mapred/org/apache/hadoop/mapred/TaskTracker.java	(working copy)
@@ -137,6 +137,12 @@
   static final long WAIT_FOR_DONE = 3 * 1000;
   private int httpPort;
 
+  public static final String TT_SHUFFLE_PROVIDER_PLUGIN = 
+		  "mapred.tasktracker.shuffle.provider.plugin";
+
+  private ShuffleProviderPlugin shuffleProviderPlugin;
+
+
   static enum State {NORMAL, STALE, INTERRUPTED, DENIED}
 
   static{
@@ -625,7 +631,7 @@
     + TaskTracker.LOCAL_SPLIT_FILE;
   }
 
-  static String getIntermediateOutputDir(String user, String jobid,
+  public static String getIntermediateOutputDir(String user, String jobid,
       String taskid) {
     return getLocalTaskDir(user, jobid, taskid) + Path.SEPARATOR
     + TaskTracker.OUTPUT;
@@ -881,6 +887,24 @@
     oobHeartbeatDamper = 
       fConf.getInt(TT_OUTOFBAND_HEARTBEAT_DAMPER, 
           DEFAULT_OOB_HEARTBEAT_DAMPER);
+
+    // loads a configured additional ShuffleProviderPlugin, if any.
+    // At this phase we only support at most one such plugin
+    // +++ NOTE: This code support load of 3rd party plugins at runtime +++
+    //
+    Class<? extends ShuffleProviderPlugin> providerClazz =
+    		fConf.getClass(TT_SHUFFLE_PROVIDER_PLUGIN,
+    				null, ShuffleProviderPlugin.class);
+    if (providerClazz != null) {
+        shuffleProviderPlugin = ReflectionUtils.newInstance(providerClazz, fConf);
+    }
+    if (shuffleProviderPlugin != null) {
+        LOG.info(" Using ShuffleProviderPlugin: " + shuffleProviderPlugin);
+        shuffleProviderPlugin.initialize(this);
+    }
+    else {
+        LOG.info(" NO ShuffleProviderPlugin will be used");
+    }
   }
 
   private void startJettyBugMonitor() {
@@ -1423,6 +1447,11 @@
       jettyBugMonitor.shutdown();
       jettyBugMonitor = null;
     }
+
+    if (shuffleProviderPlugin != null) {
+      shuffleProviderPlugin.destroy();
+      shuffleProviderPlugin = null;
+    }
   }
 
   /**
@@ -3781,11 +3810,19 @@
   /**
    * Get the default job conf for this tracker.
    */
-  JobConf getJobConf() {
+  public JobConf getJobConf() {
     return fConf;
   }
     
   /**
+   * Get the specific job conf for a running job.
+   */
+  public JobConf getJobConf(JobID jobid) {
+    return runningJobs.get(jobid).getJobConf();
+  }
+	
+  
+  /**
    * Is this task tracker idle?
    * @return has this task tracker finished and cleaned up all of its tasks?
    */
@@ -3864,7 +3901,7 @@
    * This class is used in TaskTracker's Jetty to serve the map outputs
    * to other nodes.
    */
-  public static class MapOutputServlet extends HttpServlet {
+  public static class MapOutputServlet extends HttpServlet implements ShuffleProviderPlugin {
     private static final long serialVersionUID = 1L;
     private static final int MAX_BYTES_TO_READ = 64 * 1024;
     
@@ -4084,6 +4121,12 @@
       LOG.debug("Fetcher request verfied. enc_str="+enc_str+";reply="
           +reply.substring(len-len/2, len-1));
     }
+	
+    // implementation for ShuffleProviderPlugin method. 
+    // This method is not called at the moment, since MapOutputServlet is not loaded as plugin.
+    public void initialize(TaskTracker taskTracker){
+        taskTracker.server.addInternalServlet("mapOutput", "/mapOutput", MapOutputServlet.class);
+    }
   }
   
 
Index: src/mapred/org/apache/hadoop/mapred/ReduceTask.java
===================================================================
--- src/mapred/org/apache/hadoop/mapred/ReduceTask.java	(revision 1363325)
+++ src/mapred/org/apache/hadoop/mapred/ReduceTask.java	(working copy)
@@ -94,7 +94,7 @@
 import org.apache.hadoop.metrics2.lib.MetricsRegistry;
 
 /** A Reduce task. */
-class ReduceTask extends Task {
+public class ReduceTask extends Task {
 
   static {                                        // register a ctor
     WritableFactories.setFactory
@@ -106,8 +106,11 @@
   
   private static final Log LOG = LogFactory.getLog(ReduceTask.class.getName());
   private int numMaps;
-  private ReduceCopier reduceCopier;
+  public static final String RT_SHUFFLE_CONSUMERER_PLUGIN = 
+		  "mapred.reducetask.shuffle.consumer.plugin";
 
+  private ShuffleConsumerPlugin shuffleConsumerPlugin;
+
   private CompressionCodec codec;
 
 
@@ -382,13 +385,21 @@
 
     boolean isLocal = "local".equals(job.get("mapred.job.tracker", "local"));
     if (!isLocal) {
-      reduceCopier = new ReduceCopier(umbilical, job, reporter);
-      if (!reduceCopier.fetchOutputs()) {
-        if(reduceCopier.mergeThrowable instanceof FSError) {
-          throw (FSError)reduceCopier.mergeThrowable;
+    	
+    	// loads the configured ShuffleConsumerPlugin, or the default one in case nothing is configured
+        // +++ NOTE: This code support load of 3rd party plugins at runtime +++
+        //
+    	Class<? extends ShuffleConsumerPlugin> clazz =
+    			job.getClass(RT_SHUFFLE_CONSUMERER_PLUGIN, null, ShuffleConsumerPlugin.class);
+    	shuffleConsumerPlugin = ShuffleConsumerPlugin.getShuffleConsumerPlugin(clazz, this, umbilical, job, reporter);
+    	LOG.info(" Using ShuffleConsumerPlugin : " + shuffleConsumerPlugin);
+   	
+      if (!shuffleConsumerPlugin.fetchOutputs()) {
+        if(shuffleConsumerPlugin.mergeThrowable instanceof FSError) {
+          throw (FSError)shuffleConsumerPlugin.mergeThrowable;
         }
         throw new IOException("Task: " + getTaskID() + 
-            " - The reduce copier failed", reduceCopier.mergeThrowable);
+            " - The reduce copier failed", shuffleConsumerPlugin.mergeThrowable);
       }
     }
     copyPhase.complete();                         // copy is already complete
@@ -402,7 +413,7 @@
           !conf.getKeepFailedTaskFiles(), job.getInt("io.sort.factor", 100),
           new Path(getTaskID().toString()), job.getOutputKeyComparator(),
           reporter, spilledRecordsCounter, null)
-      : reduceCopier.createKVIterator(job, rfs, reporter);
+      : shuffleConsumerPlugin.createKVIterator(job, rfs, reporter);
         
     // free up the data structures
     mapOutputFilesOnDisk.clear();
@@ -422,6 +433,10 @@
                     keyClass, valueClass);
     }
     done(umbilical, reporter);
+    if (shuffleConsumerPlugin != null) {
+    	shuffleConsumerPlugin.close();
+    	shuffleConsumerPlugin = null;
+    }
   }
 
   private class OldTrackingRecordWriter<K, V> implements RecordWriter<K, V> {
@@ -657,7 +672,7 @@
     OTHER_ERROR
   };
 
-  class ReduceCopier<K, V> implements MRConstants {
+  class ReduceCopier<K, V> extends ShuffleConsumerPlugin implements MRConstants {
 
     /** Reference to the umbilical object */
     private TaskUmbilicalProtocol umbilical;
@@ -730,11 +745,6 @@
      */
     private int ioSortFactor;
     
-    /**
-     * A reference to the throwable object (if merge throws an exception)
-     */
-    private volatile Throwable mergeThrowable;
-    
     /** 
      * A flag to indicate when to exit localFS merge
      */
@@ -1919,7 +1929,7 @@
       URLClassLoader loader = new URLClassLoader(urls, parent);
       conf.setClassLoader(loader);
     }
-    
+
     public ReduceCopier(TaskUmbilicalProtocol umbilical, JobConf conf,
                         TaskReporter reporter
                         )throws ClassNotFoundException, IOException {
@@ -2437,7 +2447,7 @@
      * first.
      */
     @SuppressWarnings("unchecked")
-    private RawKeyValueIterator createKVIterator(
+    public RawKeyValueIterator createKVIterator(
         JobConf job, FileSystem fs, Reporter reporter) throws IOException {
 
       // merge config params
Index: src/mapred/org/apache/hadoop/mapred/ShuffleConsumerPlugin.java
===================================================================
--- src/mapred/org/apache/hadoop/mapred/ShuffleConsumerPlugin.java	(revision 0)
+++ src/mapred/org/apache/hadoop/mapred/ShuffleConsumerPlugin.java	(revision 0)
@@ -0,0 +1,123 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+
+import java.io.IOException;
+import org.apache.hadoop.mapred.JobConf;
+import org.apache.hadoop.mapred.Task;
+import org.apache.hadoop.mapred.Task.TaskReporter;
+import org.apache.hadoop.mapred.ReduceTask.ReduceCopier;
+import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.hadoop.fs.FileSystem;
+
+/**
+ * ShuffleConsumerPlugin that can serve Reducers, and shuffle MOF files from tasktrackers.
+ * The tasktracker may use a matching ShuffleProviderPlugin
+ * 
+ * NOTE: This interface is also used when loading 3rd party plugins at runtime
+ * 
+ */
+public abstract class ShuffleConsumerPlugin {
+	
+	/**
+	 * Factory method for getting the ShuffleConsumerPlugin from the given class object and configure it. 
+	 * If clazz is null, this method will return instance of ReduceCopier since it is the default ShuffleConsumerPlugin 
+	 * 
+	 * @param clazz
+	 * @param reduceTask
+	 * @param umbilical
+	 * @param conf configure the plugin with this
+	 * @param reporter
+	 * @return
+	 * @throws ClassNotFoundException
+	 * @throws IOException
+	 */
+	public static ShuffleConsumerPlugin getShuffleConsumerPlugin(Class<? extends ShuffleConsumerPlugin> clazz, ReduceTask reduceTask, 
+			TaskUmbilicalProtocol umbilical, JobConf conf, TaskReporter reporter) throws ClassNotFoundException, IOException  {
+		
+		if (clazz != null) {
+			ShuffleConsumerPlugin plugin = ReflectionUtils.newInstance(clazz, conf);
+			plugin.init(reduceTask, umbilical, conf, reporter);
+			return plugin;
+		}
+
+		return reduceTask.new ReduceCopier(umbilical, conf, reporter); // default plugin is an inner class of ReduceTask
+	}
+	
+	/**
+	 * initialize this instance after it was created by factory using empty CTOR. @see getShuffleConsumerPlugin
+	 * 
+	 * @param reduceTask
+	 * @param umbilical
+	 * @param conf
+	 * @param reporter
+	 * @throws IOException
+	 */
+	public void init(ReduceTask reduceTask, TaskUmbilicalProtocol umbilical, JobConf conf, Reporter reporter) throws IOException{
+	}
+
+	/**
+	 * close and clean any resource associated with this object
+	 */
+	public void close(){
+	}
+
+	/**
+	 * fetch output of mappers from TaskTrackers
+	 * @return true iff success.  In case of failure an appropriate value may be set in mergeThrowable member
+	 * @throws IOException - this 'throws' is only for backward compatibility withReduceCopier.fetchOutputs() signature.
+	 * we don't really need it, since we use mergeThrowable member
+	 */
+	public abstract boolean fetchOutputs() throws IOException;
+
+	/**
+	 * Create a RawKeyValueIterator from copied map outputs. 
+	 * 
+	 * The iterator returned must satisfy the following constraints:
+	 *   1. Fewer than io.sort.factor files may be sources
+	 *   2. No more than maxInMemReduce bytes of map outputs may be resident
+	 *      in memory when the reduce begins
+	 *
+	 * If we must perform an intermediate merge to satisfy (1), then we can
+	 * keep the excluded outputs from (2) in memory and include them in the
+	 * first merge pass. If not, then said outputs must be written to disk
+	 * first.
+	 */
+	public abstract RawKeyValueIterator createKVIterator(JobConf job, FileSystem fs, Reporter reporter) throws IOException;
+
+
+
+	/**
+	 * A reference to the throwable object (if merge throws an exception)
+	 */
+	protected volatile Throwable mergeThrowable;
+
+	/**
+	 * a utility function that wraps Task.reportFatalError for serving sub classes that are not part of this package
+	 *    
+	 * @param reduceTask
+	 * @param id
+	 * @param throwable
+	 * @param logMsg
+	 */
+	protected void pluginReportFatalError(ReduceTask reduceTask, TaskAttemptID id, Throwable throwable, String logMsg) {	   
+		reduceTask.reportFatalError(id, throwable, logMsg);
+	}
+
+}
Index: src/mapred/mapred-default.xml
===================================================================
--- src/mapred/mapred-default.xml	(revision 1363325)
+++ src/mapred/mapred-default.xml	(working copy)
@@ -200,6 +200,32 @@
 </property>
 
 <property>
+  <name>mapred.tasktracker.shuffle.provider.plugin</name>
+  <value></value>   
+   <description>Name of an optional class whose instance will be used 
+   to answer shuffle requests at the TaskTracker side.
+   Note: This instance will serve in addition to the built-in shuffle provider (MapOutputServlet).
+   
+   The class must be an instance of 
+   org.apache.hadoop.mapred.ShuffleProviderPlugin. If the value is null, the
+   tasktracker will only use the built-in shuffle provider.
+   </description>
+</property>
+  
+<property>
+ <name>mapred.reducetask.shuffle.consumer.plugin</name>
+  <value></value>   
+   <description>Name of the class whose instance will be used 
+   to send shuffle requests at the ReduceTask side.
+   
+   The class must be an instance of 
+   org.apache.hadoop.mapred.ShuffleConsumerPlugin. If the value is null, the
+   reducetask will use org.apache.hadoop.mapred.ReduceCopier -- the built-in
+   class in Hadoop
+   </description>
+</property>  
+
+<property>
   <name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name>
   <value>5000</value>
   <description>The interval, in milliseconds, for which the tasktracker waits
