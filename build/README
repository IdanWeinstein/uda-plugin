#
# Copyright (C) 2012 Auburn University
# Copyright (C) 2012 Mellanox Technologies
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#  
# http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, 
# either express or implied. See the License for the specific language 
# governing permissions and  limitations under the License.
#
# 

#
# Mellanox UDA, a software plugin, accelerates Hadoop network and improves
# the scaling of Hadoop clusters executing data analytics intensive applications.
# A novel data moving protocol which uses RDMA in combination with an efficient 
# merge-sort algorithm enables Hadoop clusters based on Mellanox InfiniBand and 
# 10GbE and 40GbE RoCE (RDMA over Converged Ethernet) adapter cards to efficiently 
# move data between servers accelerating the Hadoop framework.
# Mellanox UDA is collaboratively developed with Auburn University.  
#

#in order to run UDA, you'll need:
#1. add line containing jar name matching your hadoop version to the end of your hadoop-env.sh.
	For Hadoop 1.x.y (including HDP) add:
	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib64/uda/uda-hadoop-1.x.jar
	OR (in case you need the older version):
	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib64/uda/uda-hadoop-1.x-v1.jar
	For CDH3u4 add:
	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib64/uda/uda-CDH3u4.jar

#2. OPTIONAL: in case your IB interface is not the default one on your machine:
#             run script set_hadoop_slave_property.sh located in /usr/lib64/uda on your slave nodes and on master node.
This script edits property "slave.host.name" located in mapred-site.xml. This property is used to represent 
the interface you want to run hadoop on. There are two ways to configure it:
		a. it can contain `hostname`-suffix (for example eagle1-ib). In this case in /etc/hosts should contain 
		an entry spesifying ip for 'eagle1-ib'.
		b. if you do not wish to edit /etc/hosts you can work with ip address of specific interface. 
		In this case, ip should appear in conf dir in slaves file, and in all xml properties where master's name is used.
Parameters to be passed to the script:
Required options:
		--hadoop-conf-dir=DIR  	path to conf dir of existing hadoop installation
	AND one of the following options:
		--interface=INTERFACE_NAME	interface name as it appears in 'ifconfig'
		--host-suffix=HOST_SUFFIX  	suffix to be added to hostname	
		
3. OPTIONAL: in case your IB interface is not the default one on your machine:
#            HDFS settings:
#Merge the following lines into your hdfs-site.xml
<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<configuration>
		<property>
			<name>dfs.datanode.dns.interface</name>
			<value>ib0</value>
			<description>The name of the Network Interface from which a
				data node should report its IP address.
			</description>
			</property>
	</configuration>
#4. TaskTracker level settings:
#   Merge the following lines into your mapred-site.xml
#   NOTE: this must be in mapred-*.xml, because it must be considered in TaskTracker initialization
#         hence, it can't be just given per job
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<configuration>

	
		 
		<property>
		  <name>mapreduce.shuffle.provider.plugin.classes</name>
		  <value>com.mellanox.hadoop.mapred.UdaShuffleProviderPlugin,org.apache.hadoop.mapred.TaskTracker$DefaultShuffleProvider</value>              
		  <description>A comma-separated list of classes that should be loaded as ShuffleProviderPlugin(s).
		   A ShuffleProviderPlugin can serve shuffle requests from reducetasks.
		   Each class in the list must be an instance of org.apache.hadoop.mapred.ShuffleProviderPlugin.
		  </description>
		</property>
		 
			
		<property>
		<name>mapred.tasktracker.shuffle.provider.plugin</name>
			<value>com.mellanox.hadoop.mapred.UdaShuffleProviderPlugin</value>	
			<description> This is if you want support for the older version: uda-hadoop-1.x-v1.jar
				represents plugin for shuffle at TaskTracker side 
				default value is: 
				(empty string)
				You can also try: 
				com.mellanox.hadoop.mapred.UdaShuffleProviderPlugin
			</description>
		</property>
			
		<!-- this one is OPTIONAL, needed: in case your IB interface is not the default one on your machine -->
		<property>
			<name>mapred.tasktracker.dns.interface</name>
			<value>ib0</value>
		</property>
		
	</configuration>


#5. Job level settings:
#   The following are ADDITIONAL setting that must be given to any UDA job.
#   it can be provided either in command line or in mapred-*.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<configuration>

		
		<property>
			<name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name>
			<value>com.mellanox.hadoop.mapred.UdaShuffleConsumerPlugin</value>
			<description>
				represents plugin for shuffle at ReduceTask side 
				default value is: 
				org.apache.hadoop.mapred.ReduceCopier
				You can also try: 
				com.mellanox.hadoop.mapred.UdaShuffleConsumerPlugin
			</description>
		</property>

	
		<property>
			<name>mapred.reducetask.shuffle.consumer.plugin</name>
			<value>com.mellanox.hadoop.mapred.UdaShuffleConsumerPlugin</value>
			<description> This is if you want support for the older version: uda-hadoop-1.x-v1.jar
				represents plugin for shuffle at ReduceTask side 
				default value is: 
				org.apache.hadoop.mapred.ReduceCopier
				You can also try: 
				com.mellanox.hadoop.mapred.UdaShuffleConsumerPlugin
			</description>
		</property>
		
		
		
	</configuration>

#6 . OPTIONAL: 
#   The following are optional parameters for UDA with their defaults
#   Users may decide to change defaults in their environment
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<configuration>
				
		<property>
			<name>mapred.rdma.cma.port</name>
			<description>Port number to be used for the RDMA connection</description>
			<value>9011</value>
		</property>
		
		<property>
			<name>mapred.rdma.wqe.per.conn</name>
			<description>Number of allocated Work Queue Elements (WQEs) for Receive
					Queue per connection
			</description>
			<value>256</value>
		</property>
		
		<property>
			<name>mapred.rdma.buf.size</name>
			<value>1024</value>
			<description>
				Used by both UdaShuffleProvider and UdaShuffleConsumer:
				- UdaShuffleProvider (TaskTracker): determines the RDMA&AIO Buffers size to satify Map Output's RDMA fetch requests
				- UdaShuffleConsumer (Reducer): user prefered RDMA buffer size for fetching  map outputs
				Size in KB and must be alligned to page size.
			</description>
		</property>
		
		<property>
			<name>mapred.rdma.buf.size.min</name>
			<value>32</value>
			<description>
				UDA reducer allocates RDMA buffers according to 'mapred.rdma.buf.size'
				If the buffer size is too big then a smaller buffer will be used while 'mapred.rdma.buf.size.min' is the limit.
				Bigger RDMA buffers improves the shuffle performance. 
				Too small buffer size can sagnificantly reduce the perfomance.
				Task will fail in case the redcuer need to use smaller buffer size than 'mapred.rdma.buf.size.min'.
			</description>
		</property>
		
		<property>
			<name>mapred.rdma.compression.buffer.ratio</name>
			<description>The ratio in which memory is divided between RDMA buffer and decompression buffer (used only with intermediate data compression)</description>
			<value>0.20</value>
		</property>
	
	</configuration>

7. OPTIONAL - debug logs:
UDA debug logs configuration and output are available thru Hadoop standard log configuration and log files.
For example to debug the client side (NetMerger) at TRACE level and the server side (MofSupplier) at DEBUG level, add the following 2 lines to your log4j.properties file:

	log4j.logger.org.apache.hadoop.mapred.ShuffleConsumerPlugin=TRACE
	log4j.logger.org.apache.hadoop.mapred.ShuffleProviderPlugin=DEBUG

The log output from UDA client will be in the log file of the appropriate Reduce Task.
The log output from UDA server will be in the log file of the appropriate Task Tracker.
